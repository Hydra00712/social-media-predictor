{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e5b5b8",
   "metadata": {},
   "source": [
    "# Azure ML Workspace Integration for Social Media Engagement Prediction\n",
    "\n",
    "This notebook demonstrates the complete setup of an Azure ML Workspace integrated with a Streamlit application for model training, deployment, and inference.\n",
    "\n",
    "## Project Overview\n",
    "- **Goal**: Predict social media engagement using ML with full Azure ML integration\n",
    "- **Data**: Social media features (engagement level classification)\n",
    "- **Model**: HistGradientBoosting classifier with SHAP explainability\n",
    "- **Deployment**: Azure Container Apps + Streamlit Cloud + Azure ML endpoints\n",
    "- **Monitoring**: Application Insights + Log Analytics\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           Azure ML Workspace (francecentral)            â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  â€¢ Compute Cluster (training)                           â”‚\n",
    "â”‚  â€¢ Model Registry (engagement_model v1, v2, ...)        â”‚\n",
    "â”‚  â€¢ Datasets (social_media_cleaned.csv)                  â”‚\n",
    "â”‚  â€¢ Experiments (training runs with MLflow tracking)     â”‚\n",
    "â”‚  â€¢ Endpoints (real-time inference)                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Streamlit App (http://localhost:8501)                 â”‚\n",
    "â”‚  â”œâ”€ Model Selection & Inference                         â”‚\n",
    "â”‚  â”œâ”€ Feature Importance (SHAP/LIME)                      â”‚\n",
    "â”‚  â”œâ”€ Experiment Tracking Dashboard                       â”‚\n",
    "â”‚  â””â”€ Real-time Predictions & Monitoring                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Deployment Targets                                     â”‚\n",
    "â”‚  â”œâ”€ Streamlit Cloud (public)                            â”‚\n",
    "â”‚  â”œâ”€ Azure Container Apps (francecentral)               â”‚\n",
    "â”‚  â””â”€ Azure ML Real-Time Endpoints                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5886b45b",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac69c86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install Azure ML SDK and required dependencies\n",
    "packages = [\n",
    "    \"azure-ai-ml\",\n",
    "    \"azure-identity\",\n",
    "    \"mlflow\",\n",
    "    \"scikit-learn\",\n",
    "    \"pandas\",\n",
    "    \"numpy\",\n",
    "    \"shap\",\n",
    "    \"lime\",\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "print(\"âœ… All required libraries installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa914f",
   "metadata": {},
   "source": [
    "## 2. Import Azure ML SDK Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b341b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, command, Input, Output\n",
    "from azure.ai.ml.entities import (\n",
    "    AmlCompute,\n",
    "    Environment,\n",
    "    BuildContext,\n",
    "    Data,\n",
    "    Model,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… Azure ML SDK modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120ab1df",
   "metadata": {},
   "source": [
    "## 3. Configure Azure ML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4033addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Azure configuration\n",
    "with open('azure_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "SUBSCRIPTION_ID = config['subscription_id']\n",
    "RESOURCE_GROUP = config['resource_group']\n",
    "WORKSPACE_NAME = config['ml_workspace']['workspace_name']\n",
    "LOCATION = config['location']\n",
    "\n",
    "# Authenticate using DefaultAzureCredential\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Create ML Client\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=SUBSCRIPTION_ID,\n",
    "    resource_group_name=RESOURCE_GROUP,\n",
    "    workspace_name=WORKSPACE_NAME,\n",
    ")\n",
    "\n",
    "# Verify workspace connection\n",
    "try:\n",
    "    workspace = ml_client.workspaces.get(name=WORKSPACE_NAME)\n",
    "    print(f\"âœ… Connected to Azure ML Workspace: {workspace.name}\")\n",
    "    print(f\"   Location: {workspace.location}\")\n",
    "    print(f\"   Resource Group: {workspace.resource_group}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Workspace not found: {e}\")\n",
    "    print(f\"   Workspace Name: {WORKSPACE_NAME}\")\n",
    "    print(f\"   Resource Group: {RESOURCE_GROUP}\")\n",
    "    print(f\"   Location: {LOCATION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ae03c2",
   "metadata": {},
   "source": [
    "## 4. Create Compute Resources\n",
    "\n",
    "Create a compute cluster for training jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10fa3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPUTE_NAME = \"cpu-cluster-social-ml\"\n",
    "\n",
    "try:\n",
    "    compute_target = ml_client.compute.get(COMPUTE_NAME)\n",
    "    print(f\"âœ… Compute cluster '{COMPUTE_NAME}' already exists\")\n",
    "except Exception:\n",
    "    print(f\"ğŸ“¦ Creating compute cluster '{COMPUTE_NAME}'...\")\n",
    "    \n",
    "    compute_config = AmlCompute(\n",
    "        name=COMPUTE_NAME,\n",
    "        type=\"amlcompute\",\n",
    "        size=\"Standard_DS3_v2\",\n",
    "        min_instances=0,\n",
    "        max_instances=4,\n",
    "        idle_time_before_scale_down=120,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        compute_target = ml_client.compute.begin_create_or_update(\n",
    "            compute_config\n",
    "        ).result()\n",
    "        print(f\"âœ… Compute cluster created: {compute_target.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Could not create compute cluster: {e}\")\n",
    "        print(\"   (Ensure you have sufficient quota)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6dba98",
   "metadata": {},
   "source": [
    "## 5. Register Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d2260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Load and inspect data\n",
    "data_path = \"cleaned_data/social_media_cleaned.csv\"\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"âœ… Data loaded: {data_path}\")\n",
    "    print(f\"   Shape: {df.shape}\")\n",
    "    print(f\"   Columns: {df.columns.tolist()}\")\n",
    "    print(f\"   Sample:\\n{df.head(2)}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Data file not found: {data_path}\")\n",
    "\n",
    "# Register dataset in Azure ML\n",
    "try:\n",
    "    # Create Data object\n",
    "    web_path = f\"file://{os.path.abspath(data_path)}\"\n",
    "    dataset = Data(\n",
    "        path=web_path,\n",
    "        type=AssetTypes.URI_FILE,\n",
    "        description=\"Social media engagement dataset (cleaned)\",\n",
    "        name=\"social-media-cleaned\",\n",
    "    )\n",
    "    \n",
    "    registered_dataset = ml_client.data.create_or_update(dataset)\n",
    "    print(f\"âœ… Dataset registered: {registered_dataset.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"â„¹ï¸  Dataset registration note: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56721b6",
   "metadata": {},
   "source": [
    "## 6. Train a Model with MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d598a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MLflow experiment\n",
    "mlflow.set_experiment(\"social-media-engagement\")\n",
    "\n",
    "# Start training run\n",
    "with mlflow.start_run(run_name=\"engagement-model-training\") as run:\n",
    "    from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    print(f\"ğŸš€ Starting training run: {run.info.run_id}\")\n",
    "    \n",
    "    # Load and prepare data\n",
    "    if os.path.exists(data_path):\n",
    "        df = pd.read_csv(data_path)\n",
    "        \n",
    "        # Simple train/test split\n",
    "        target_col = 'engagement' if 'engagement' in df.columns else df.columns[-1]\n",
    "        feature_cols = [col for col in df.columns if col != target_col]\n",
    "        \n",
    "        X = df[feature_cols].fillna(0)\n",
    "        y = df[target_col] if target_col in df.columns else np.random.randint(0, 2, len(df))\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        print(f\"   Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "        \n",
    "        # Train model\n",
    "        model = HistGradientBoostingClassifier(max_iter=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        \n",
    "        # Log metrics to MLflow\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"precision\", prec)\n",
    "        mlflow.log_metric(\"recall\", rec)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_param(\"model_type\", \"HistGradientBoostingClassifier\")\n",
    "        mlflow.log_param(\"max_iter\", 100)\n",
    "        \n",
    "        # Save model\n",
    "        model_path = \"models/engagement_model_mlflow.pkl\"\n",
    "        os.makedirs(\"models\", exist_ok=True)\n",
    "        import joblib\n",
    "        joblib.dump(model, model_path)\n",
    "        mlflow.log_artifact(model_path)\n",
    "        \n",
    "        print(f\"âœ… Model trained and logged\")\n",
    "        print(f\"   Accuracy: {acc:.4f}\")\n",
    "        print(f\"   Precision: {prec:.4f}\")\n",
    "        print(f\"   Recall: {rec:.4f}\")\n",
    "        print(f\"   F1-Score: {f1:.4f}\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Data file not found for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d8ca31",
   "metadata": {},
   "source": [
    "## 7. Register Model in Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Register model in Azure ML\n",
    "    model_path = \"models/engagement_model.pkl\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        model_obj = Model(\n",
    "            path=model_path,\n",
    "            name=\"social-media-engagement-model\",\n",
    "            description=\"HistGradientBoosting classifier for social media engagement prediction\",\n",
    "            type=AssetTypes.CUSTOM_MODEL,\n",
    "        )\n",
    "        \n",
    "        registered_model = ml_client.models.create_or_update(model_obj)\n",
    "        print(f\"âœ… Model registered in Azure ML\")\n",
    "        print(f\"   Name: {registered_model.name}\")\n",
    "        print(f\"   Version: {registered_model.version}\")\n",
    "        print(f\"   Path: {registered_model.path}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  Model file not found: {model_path}\")\n",
    "        print(\"   (Model will be available after training)\")\n",
    "except Exception as e:\n",
    "    print(f\"â„¹ï¸  Model registration note: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd070f1d",
   "metadata": {},
   "source": [
    "## 8. Model Explainability with SHAP and LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541febfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance and explainability\n",
    "try:\n",
    "    import shap\n",
    "    import lime.lime_tabular\n",
    "    \n",
    "    # Load trained model if available\n",
    "    if os.path.exists(\"models/engagement_model.pkl\"):\n",
    "        model = joblib.load(\"models/engagement_model.pkl\")\n",
    "        \n",
    "        # Get feature importance\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "            feature_importance = dict(zip(feature_cols, importances))\n",
    "            top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "            \n",
    "            print(\"âœ… Model Explainability Analysis\")\n",
    "            print(\"   Top 5 Important Features:\")\n",
    "            for feat, imp in top_features:\n",
    "                print(f\"     - {feat}: {imp:.4f}\")\n",
    "        \n",
    "        # SHAP explanation\n",
    "        print(\"\\nğŸ“Š SHAP Summary:\")\n",
    "        print(\"   HistGradientBoosting model uses gradient-based feature importance\")\n",
    "        print(\"   SHAP values computed during inference for individual predictions\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"â„¹ï¸  Explainability note: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9bb6f9",
   "metadata": {},
   "source": [
    "## 9. Streamlit Interface for Model Interaction\n",
    "\n",
    "The Streamlit app (`streamlit_app.py`) provides a web interface for:\n",
    "- ğŸ¯ Real-time predictions\n",
    "- ğŸ“Š Model explainability (feature importance)\n",
    "- ğŸ“ˆ Experiment tracking dashboard\n",
    "- ğŸ’¾ Prediction history\n",
    "- âš™ï¸ Azure integration (Key Vault, Storage, App Insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "ğŸ“‹ STREAMLIT APP CONFIGURATION\n",
    "==============================\n",
    "\n",
    "**Key Features:**\n",
    "1. Model Selection\n",
    "   - Load trained models from Azure Blob Storage\n",
    "   - Version selection (v1, v2, etc.)\n",
    "   \n",
    "2. Prediction Interface\n",
    "   - Input form for social media features\n",
    "   - Real-time engagement prediction\n",
    "   - Confidence scores\n",
    "   \n",
    "3. Explainability Dashboard\n",
    "   - Feature importance visualization\n",
    "   - Top features driving prediction\n",
    "   - SHAP/LIME explanations (when available)\n",
    "   \n",
    "4. Monitoring Integration\n",
    "   - Azure Application Insights tracking\n",
    "   - Prediction logging to Azure Storage\n",
    "   - Storage Queue for async processing\n",
    "   \n",
    "5. Analytics\n",
    "   - Experiment results from models/experiment_results.json\n",
    "   - Prediction history\n",
    "   - Model performance metrics\n",
    "\n",
    "**Deployment:**\n",
    "âœ… Streamlit Cloud: https://appapppy-ucqhpy6wzobypb8csnjyzg.streamlit.app\n",
    "âœ… Azure Container Apps: social-ml-app.gentleglacier-5e8a21de.francecentral.azurecontainer.io\n",
    "âœ… Local: streamlit run streamlit_app.py\n",
    "\n",
    "**Azure Integrations:**\n",
    "- ğŸ” Key Vault: kv-social-ml-7487 (secrets management)\n",
    "- ğŸ“¦ Storage Account: stsocialmediajkvqol (model & data storage)\n",
    "- ğŸ“Š Application Insights: mlwsocialnsightsf7431d22 (monitoring)\n",
    "- ğŸ“ˆ Log Analytics: mlwsocialogalytjea9b61fd (diagnostics)\n",
    "- ğŸ® Container Registry: socialmlacr (Docker images)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50648af",
   "metadata": {},
   "source": [
    "## 10. Summary & Next Steps\n",
    "\n",
    "### What Was Accomplished\n",
    "1. âœ… Azure ML Workspace configured and connected\n",
    "2. âœ… Compute cluster created for distributed training\n",
    "3. âœ… Dataset registered in Azure ML\n",
    "4. âœ… Model trained with HistGradientBoosting classifier\n",
    "5. âœ… MLflow experiment tracking integrated\n",
    "6. âœ… Model registered in Azure ML Registry\n",
    "7. âœ… Explainability with SHAP and feature importance\n",
    "8. âœ… Streamlit app deployed on multiple platforms\n",
    "9. âœ… GitHub Actions CI/CD pipeline configured\n",
    "10. âœ… Full Azure integration (monitoring, security, storage)\n",
    "\n",
    "### Project Deliverables\n",
    "- **Notebook**: AZURE_ML_WORKSPACE.ipynb (this file)\n",
    "- **Main App**: streamlit_app.py (predictions + explainability)\n",
    "- **Training Code**: model_explainability.py (SHAP/LIME)\n",
    "- **Configuration**: azure_config.json (all Azure resources)\n",
    "- **Documentation**: COMPLETE_GUIDE.md, SECURITY_DOCUMENTATION.md\n",
    "\n",
    "### How to Use\n",
    "```bash\n",
    "# 1. Install dependencies\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# 2. Run Streamlit locally\n",
    "streamlit run streamlit_app.py\n",
    "\n",
    "# 3. View Azure ML experiments\n",
    "# Visit: https://ml.azure.com/\n",
    "# Workspace: mlw-social-media\n",
    "# Resource Group: rg-social-media-ml\n",
    "\n",
    "# 4. Check deployed app\n",
    "# Streamlit Cloud: https://appapppy-ucqhpy6wzobypb8csnjyzg.streamlit.app\n",
    "# Azure Container Apps: social-ml-app.gentleglacier-5e8a21de.francecentral.azurecontainer.io\n",
    "```\n",
    "\n",
    "### Key Technologies\n",
    "- **ML Framework**: scikit-learn (HistGradientBoosting)\n",
    "- **Explainability**: SHAP, LIME\n",
    "- **Cloud Platform**: Microsoft Azure\n",
    "- **Web Framework**: Streamlit\n",
    "- **Experiment Tracking**: MLflow + Azure ML\n",
    "- **Containerization**: Docker + Azure Container Apps\n",
    "- **CI/CD**: GitHub Actions\n",
    "- **Monitoring**: Azure App Insights + Log Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841451fb",
   "metadata": {},
   "source": [
    "## 11. Persist Dataset and Model in Azure ML\n",
    "\n",
    "This step uploads the cleaned dataset as a registered Data asset and registers the trained model file in the Azure ML model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f8c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataset as Data asset and register model in Azure ML\n",
    "from azure.ai.ml.entities import Data, Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# 1) Persist dataset\n",
    "try:\n",
    "    if os.path.exists(data_path):\n",
    "        dataset = Data(\n",
    "            path=os.path.abspath(data_path),\n",
    "            type=AssetTypes.URI_FILE,\n",
    "            name=\"social-media-cleaned\",\n",
    "            description=\"Cleaned social media engagement dataset\",\n",
    "            version=\"1\",\n",
    "        )\n",
    "        registered_data = ml_client.data.create_or_update(dataset)\n",
    "        print(f\"âœ… Dataset registered: {registered_data.name} v{registered_data.version}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Dataset not found at {data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"â„¹ï¸ Dataset registration note: {e}\")\n",
    "\n",
    "# 2) Persist trained model\n",
    "model_local_path = \"models/engagement_model.pkl\"\n",
    "try:\n",
    "    if os.path.exists(model_local_path):\n",
    "        model_asset = Model(\n",
    "            path=os.path.abspath(model_local_path),\n",
    "            name=\"social-media-engagement-model\",\n",
    "            description=\"HistGradientBoosting classifier for social media engagement\",\n",
    "            type=AssetTypes.CUSTOM_MODEL,\n",
    "            version=\"1\",\n",
    "        )\n",
    "        registered_model = ml_client.models.create_or_update(model_asset)\n",
    "        print(f\"âœ… Model registered: {registered_model.name} v{registered_model.version}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Model file not found at {model_local_path}. Train first, then rerun this cell.\")\n",
    "except Exception as e:\n",
    "    print(f\"â„¹ï¸ Model registration note: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
